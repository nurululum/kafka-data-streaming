# Documentation

1. Docker build and run

2. Create topic
<p align="center">
  <img width="1396" alt="create topic" src="https://github.com/nurululum/kafka-data-streaming/assets/116478678/530c0432-3103-4e81-9065-c41071bf5920">
</p>

3. Run script for push data from data source to kafka
<p align="center">
  <img width="990" alt="push raw data from data source to kafka" src="https://github.com/nurululum/kafka-data-streaming/assets/116478678/af0db694-547f-45b0-9e64-89cb887a4de4">
</p>

4. Run script for check consumer topic nurul-data-raw
<p align="center">
  <img width="1036" alt="check consumer topic data-raw" src="https://github.com/nurululum/kafka-data-streaming/assets/116478678/fd799a9c-4d8f-4547-934c-7d61205971f9">
</p>

5. Run script ETL script using spark streaming
<p align="center">
  <img width="1038" alt="ETL script using spark streaming" src="https://github.com/nurululum/kafka-data-streaming/assets/116478678/4e0bba17-dae4-4c9b-bb71-2b05e87b068e">
</p>

6. Run script for check consumer topic nurul-data-clean
<p align="center">
  <img width="922" alt="check consumer topic data-clean" src="https://github.com/nurululum/kafka-data-streaming/assets/116478678/09d976c5-26b5-4b1f-9eb0-777ea1324def">
</p>

7. Connect to realtime dashboard
<p align="center">
  <img width="1160" alt="dashboard" src="https://github.com/nurululum/kafka-data-streaming/assets/116478678/07e006a3-7c4b-41ff-baaf-28786468e21d">
</p>
